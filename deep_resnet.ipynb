{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "A deep resnet trained on the pokemon image dataset for type prediction. The preprocessing was done according to https://www.kaggle.com/bishetheanswer/pokemon-image-dataset-ready-for-type-prediction."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "seed = 27912\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"downloaded_datasets/pokemon/pokemon.csv\")\n",
    "data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = data.Type1.unique()\n",
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"downloaded_datasets/pokemon/newData_pokemon\")\n",
    "\n",
    "for t in types:\n",
    "    os.mkdir(\"downloaded_datasets/pokemon/newData_pokemon/{}\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = \"downloaded_datasets/pokemon/images/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in types:\n",
    "    aux_type = data[data.Type1.eq(t)]\n",
    "    for pokemon in aux_type.Name:\n",
    "        for filename in os.listdir(images_dir):\n",
    "            original_path = \"{}{}\".format(images_dir, filename)\n",
    "            # pokemon name with extension\n",
    "            extension = os.path.basename(original_path)\n",
    "            # directory without extension\n",
    "            poke_dir = os.path.splitext(original_path)[0]\n",
    "            # only pokemon name\n",
    "            poke_name = os.path.basename(poke_dir)\n",
    "            if(pokemon == poke_name):\n",
    "                target_path = \"downloaded_datasets/pokemon/newData_pokemon/{}/{}\".format(t, extension)\n",
    "                shutil.copyfile(original_path, target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_color = (255, 255, 255)\n",
    "new_images_dir = \"downloaded_datasets/pokemon/newData_pokemon/\"\n",
    "\n",
    "for t in types:\n",
    "    for filename in os.listdir(new_images_dir):\n",
    "        type_dir = \"{}{}/\".format(new_images_dir, filename)\n",
    "        for pokemon in os.listdir(type_dir):\n",
    "            full_path = \"{}/{}\".format(type_dir, pokemon)\n",
    "            file_dir, file_extension = os.path.splitext(full_path)\n",
    "            if file_extension == \".png\":\n",
    "                im = Image.open(full_path)\n",
    "                im = im.convert(\"RGBA\")\n",
    "                if im.mode in ('RGBA', 'LA'):\n",
    "                    bg = Image.new(im.mode[:-1], im.size, fill_color)\n",
    "                    bg.paste(im, im.split()[-1])  # omit transparency\n",
    "                    bg.save(\"{}.jpg\".format(file_dir))\n",
    "                    os.remove(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = \"downloaded_datasets/pokemon/newData_pokemon/\"\n",
    "output_filename = \"pokemon_data\"\n",
    "\n",
    "shutil.make_archive(output_filename, 'zip', dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 120\n",
    "img_width = 120\n",
    "new_images_dir = \"downloaded_datasets/pokemon/newData_pokemon/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    new_images_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    image_size = (img_height, img_width),\n",
    "    seed=seed,\n",
    "    label_mode='categorical',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    new_images_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    image_size = (img_height,img_width),\n",
    "    seed=seed,\n",
    "    label_mode='categorical',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "print(len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_class_names = {}\n",
    "for i in range(18):\n",
    "    idx_to_class_names[i] = class_names[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(idx_to_class_names[np.argmax(labels[i])])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, labels in train_ds:\n",
    "    print(image.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, filters):\n",
    "    F1, F2, F3 = filters\n",
    "    X_shortcut = X\n",
    "    X = layers.Conv2D(F1, (1,1))(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Activation(\"relu\")(X)\n",
    "    X = layers.Conv2D(F2, (3,3), padding=\"same\")(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Activation(\"relu\")(X)\n",
    "    X = layers.Conv2D(F3, (1,1))(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Add()([X, X_shortcut])\n",
    "    X = layers.Activation(\"relu\")(X)\n",
    "    return X\n",
    "\n",
    "def convolutional_block(X, filters, s=2):\n",
    "    F1, F2, F3 = filters\n",
    "    X_shortcut = X\n",
    "    X = layers.Conv2D(F1, (1,1), strides=(s,s))(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Activation(\"relu\")(X)\n",
    "    X = layers.Conv2D(F2, (3,3), padding=\"same\")(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Activation(\"relu\")(X)\n",
    "    X = layers.Conv2D(F3, (1,1))(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X_shortcut = layers.Conv2D(F3, (1,1),strides=(s,s))(X_shortcut)\n",
    "    X_shortcut = layers.BatchNormalization()(X_shortcut)\n",
    "    X = layers.Add()([X, X_shortcut])\n",
    "    X = layers.Activation(\"relu\")(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet(input_shape):\n",
    "    X_input = tf.keras.Input(input_shape)\n",
    "    X = layers.Conv2D(64, (3,3), padding=\"same\")(X_input)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.MaxPooling2D()(X)\n",
    "    X = convolutional_block(X, filters=[64,64,256], s=1)\n",
    "    X = identity_block(X, filters=[64,64,256])\n",
    "    X = identity_block(X, filters=[64,64,256])\n",
    "    X = identity_block(X, filters=[64,64,256])\n",
    "    X = convolutional_block(X, filters=[128,128,512])\n",
    "    X = identity_block(X, filters=[128,128,512])\n",
    "    X = identity_block(X, filters=[128,128,512])\n",
    "    X = identity_block(X, filters=[128,128,512])\n",
    "    X = convolutional_block(X, filters=[256,256,1024])\n",
    "    X = identity_block(X, filters=[256,256,1024])\n",
    "    X = identity_block(X, filters=[256,256,1024])\n",
    "    X = identity_block(X, filters=[256,256,1024])\n",
    "    X = convolutional_block(X, filters=[512,512,2048])\n",
    "    X = identity_block(X, filters=[512,512,2048])\n",
    "    X = identity_block(X, filters=[512,512,2048])\n",
    "    X = identity_block(X, filters=[512,512,2048])\n",
    "    X = layers.AveragePooling2D()(X)\n",
    "    X = layers.Flatten()(X)\n",
    "    X = layers.Dense(18, activation=\"softmax\")(X)\n",
    "    model = tf.keras.models.Model(inputs = X_input, outputs=X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet(input_shape=(120,120,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, to_file=\"models/deep_resnet.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds, epochs=30, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}